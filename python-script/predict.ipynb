{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('models/vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/Logistic Regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ahayd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "def procces_sentence(review:str)->str:\n",
    "    sample_review = re.sub(r'http\\S+', '', review)\n",
    "    sample_review = re.sub(\"[^a-zA-Z]\",' ',sample_review)\n",
    "    sample_review = sample_review.lower()\n",
    "    sample_review = sample_review.split()\n",
    "    swords = set(stopwords.words(\"english\"))                     \n",
    "    sample_review = [w for w in sample_review if w not in swords]        \n",
    "    sample_review = \" \".join(sample_review)\n",
    "    return sample_review\n",
    "\n",
    "\n",
    "def predict_sentiment(new_sentence:str, model, vectorizer)->str:\n",
    "    cleaned_sentence = procces_sentence(new_sentence)\n",
    "    new_sentence_vector = vectorizer.transform([cleaned_sentence])\n",
    "    new_sentence_vector = new_sentence_vector.toarray()\n",
    "    prediction = model.predict(new_sentence_vector)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Neutral\n",
      "Max Probability: 81.39%\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(sentence: str, model, catboost=False):\n",
    "    processed_sentence = procces_sentence(sentence)\n",
    "    vectorized_sentence = vectorizer.transform([processed_sentence]).toarray()\n",
    "    prediction = model.predict(vectorized_sentence)\n",
    "    probabilities = model.predict_proba(vectorized_sentence)\n",
    "    \n",
    "    sentiment_map = {0: 'Neutral', 1: 'Negative', 2: 'Positive'}\n",
    "\n",
    "    if catboost:\n",
    "        predicted_class = int(prediction[0][0])\n",
    "    else:\n",
    "        predicted_class = prediction[0]\n",
    "\n",
    "    predicted_sentiment = sentiment_map[predicted_class]\n",
    "\n",
    "    print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
    "    max_probability = max(probabilities[0]) * 100\n",
    "    print(f\"Max Probability: {max_probability:.2f}%\")\n",
    "\n",
    "new_sentence = \"Attending a virtual conference on AI\"\n",
    "predict_sentiment(new_sentence, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
